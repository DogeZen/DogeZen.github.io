---
title: 预处理:标签平滑
date: 2021-07-15 08:00:00
tags:  
- 预处理
---

```python
def CrossEntropyLoss_label_smooth(outputs, targets,
                                  num_classes=2, epsilon=0.1):
    N = targets.size(0)
    smoothed_labels = torch.full(size=(N, num_classes),
                                 fill_value=epsilon / (num_classes - 1))
    targets = targets.data.cpu()
    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(targets, dim=1),
                             value=1 - epsilon)
    # outputs = outputs.data.cpu()
    log_prob = nn.functional.log_softmax(outputs, dim=1).cpu()
    loss = - torch.sum(log_prob * smoothed_labels) / N
    return loss
loss = CrossEntropyLoss_label_smooth(outputs, labels, num_classes=2)
```

参考[GitHub – genhao3/PET: 科大讯飞2020脑PET图像分析和疾病预测—单模型进决赛前五](https://github.com/genhao3/PET)

原理参考[标签平滑&深度学习：Google Brain解释了为什么标签平滑有用以及什么时候使用它 – 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/101553787)

## 简单解释

对于常规的独热标签，为了防止出现局部最优的现象，本步骤中对样本生成的独热编码进行平滑，增大分类的泛化能力，具体步骤如下：
1）获取标签个数
2）根据标签个数和类别个数生成平滑单位矩阵，里面的值以既定平滑系数/（类别数-1）
3）标签数值平滑，即对数值为1的位置项该值减去平滑系数，其余项加上平滑系数的倒数，生成符合原标签数值分布的标签系数矩阵
4）然后对原标签矩阵进行对数交叉熵映射，然后对映射后的结果乘以平滑后的标签系数矩阵生成最终的标签矩阵。